# AI
Artificial Intelligence
<hr/>

##1. Artificial Neural Networks [(Jeff Heaton)](http://www.heatonresearch.com/), English

* Fundamentals

>* [Input and Output](https://www.youtube.com/watch?v=PNqc4fkdfIo&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2&index=1)
* [Classification](https://www.youtube.com/watch?v=4KaGedHXfTg&index=2&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2)
* [Regression](https://www.youtube.com/watch?v=wLQs5Kj17xY&index=3&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2)
* [Prediction](https://www.youtube.com/watch?v=52IK5wHSkrA&index=4&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2)

* Calculation

>* [Feedforward Structure](https://www.youtube.com/watch?v=ujBiM9stPHU&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2&index=5)
* [Activation Functions & Basic Calculation](https://www.youtube.com/watch?v=LW9VnXVIQt4&index=6&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2)
* [Feedforward Neural Network](https://www.youtube.com/watch?v=OWhGyPgts5U&index=7&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2)
* [Elman Neural Network SRN Calculation](https://www.youtube.com/watch?v=e2sGq_vI41s&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2&index=8)
* [Jordan Neural Network SRN Calculation](https://www.youtube.com/watch?v=yXTM_UUuYY0&index=9&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2)

* Training

>* [The Training Process](https://www.youtube.com/watch?v=CVJOseIJnww&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2&index=10)
* [Neural Network Error Calculation](https://www.youtube.com/watch?v=U4BTzF3Wzt0&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2&index=11)
* [Gradient Calculation](https://www.youtube.com/watch?v=p1-FiWjThs8&index=12&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2)
* [Backpropagation](https://www.youtube.com/watch?v=IruMm7mPDdM&list=PLiPvV5TNogxJoK7Y3z6kjc_jgtM3Se-u2&index=13)

##2. Neural Networks for Machine Learning by Geoffrey Hinton [(Coursera 2013)](https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0), English

>Heavy on theory, not for beginners

* [L1 : Introduction](https://www.youtube.com/watch?v=2fRnHVVLf1Y&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=6)

>* [Why do we need machine learning?](https://www.youtube.com/watch?v=4w0_mJ_6QoI&index=1&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [What are neural networks?](https://www.youtube.com/watch?v=0JrfYvn8zns&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=2)
* [Some simple models of neurons](https://www.youtube.com/watch?v=z9lE4cowVFw&index=3&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [A simple example of learning](https://www.youtube.com/watch?v=iryPlswgRSA&index=4&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Three types of learning](https://www.youtube.com/watch?v=7IUhZ_XOYeU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=5)

* [L2 : The Perceptron learning procedure](https://www.youtube.com/watch?v=oID20dIrV94&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=12)

>* [An overview of the main types of neural network architecture](https://www.youtube.com/watch?v=KUV-r3yEri4&index=7&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Perceptrons: The first generation of neural networks](https://www.youtube.com/watch?v=TVJBOQzIKLY&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=8)
* [A geometrical view of perceptrons](https://www.youtube.com/watch?v=X-H2T9uv8Kg&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=9)
* [Why the learning works](https://www.youtube.com/watch?v=hsgyh4NaP7U&index=10&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [What perceptrons can't do](https://www.youtube.com/watch?v=BNcvqxohlXQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=11)

* [L3 : The backpropagation learning procedure](https://www.youtube.com/watch?v=a_v1DFjWYhY&index=18&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

>* [Learning the weights of a linear neuron](https://www.youtube.com/watch?v=-ducAlST5ag&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=13)
* [The error surface for a linear neuron](https://www.youtube.com/watch?v=g2c0AlazcaU&index=14&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Learning the weights of a logistic output neuron](https://www.youtube.com/watch?v=dSmtyGrCdx4&index=15&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [The backpropagation algorithm](https://www.youtube.com/watch?v=XPFZwKSQkfM&index=16&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [How to use the derivatives computed by the backpropagation algorithm](https://www.youtube.com/watch?v=AMT9raJ2SUU&index=17&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L4 : Learning feature vectors for words](https://www.youtube.com/watch?v=Rtk_juucCHc&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=24)

>* [Learning to predict the next word](https://www.youtube.com/watch?v=EHmvRc9_QR8&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=19)
* [A brief diversion into cognitive science](https://www.youtube.com/watch?v=nudLcXmJ8_w&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=20)
* [Another diversion : The softmax output function](https://www.youtube.com/watch?v=2-F1L-StqXU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=21)
* [Neuro-probabilistic language models](https://www.youtube.com/watch?v=6IzhQvg0tNA&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=22)
* [Ways to deal with the large number of possible outputs in neuro-probabilistic language models](https://www.youtube.com/watch?v=qzONfNBKUJM&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=23)

* [L5 : Object recognition with neural nets](https://www.youtube.com/watch?v=RTLI2K5OcWw&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=29)

>* [Why object recognition is difficult](https://www.youtube.com/watch?v=gsmUhuboJd0&index=25&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Ways to achieve viewpoint invariance](https://www.youtube.com/watch?v=6s5Yp7iVHgI&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=26)
* [Convolutional neural networks for hand-written digit recognition](https://www.youtube.com/watch?v=gtYo1fB2lfE&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=27)
* [Convolutional neural networks for object recognition](https://www.youtube.com/watch?v=95LF9E8qj-Q&index=28&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L6 : Optimization: How to make the learning go faster](https://www.youtube.com/watch?v=bkjfbS_wnIk&index=35&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

>* [Overview of mini batch gradient descent](https://www.youtube.com/watch?v=tCTfb6PAr4w&index=30&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [A bag of tricks for mini batch gradient descent](https://www.youtube.com/watch?v=A4fEPcrrjU4&index=31&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [The momentum method](https://www.youtube.com/watch?v=N18Km9YIIug&index=32&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [ separate, adaptive learning rate for each connection](https://www.youtube.com/watch?v=76lj_cKBvmg&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=33)
* [rmsprop: Divide the gradient by a running average of its recent magnitude](https://www.youtube.com/watch?v=SJ48OZ_qlrc&index=34&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L7 : Recurrent neural networks](https://www.youtube.com/watch?v=9T2X6WRUwFU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=41)

>* [Modeling sequences: A brief overview](https://www.youtube.com/watch?v=eT1XsQbc_Sk&index=36&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Training RNNs with backpropagation](https://www.youtube.com/watch?v=iPiVj4fuJO0&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=37)
* [A toy example of training an RNN](https://www.youtube.com/watch?v=NT5Sm7AJRwc&index=38&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Why it is difficult to train an RNN](https://www.youtube.com/watch?v=KJK2muqrlpQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=39)
* [Long term short term memory](https://www.youtube.com/watch?v=uVzrIjkE-Mo&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=40)

* [L8 : More recurrent neural networks](https://www.youtube.com/watch?v=_gZ1NcYoVv4&index=46&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

>* [A brief overview of "Hessian-Free" optimization](https://www.youtube.com/watch?v=Gqn_8GIG-iY&index=42&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Modeling character strings with multiplicative connections](https://www.youtube.com/watch?v=5zCdUg1w6oQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=43)
* [Learning to predict the next character using HF](https://www.youtube.com/watch?v=tC6Yf9_Wry8&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=44)
* [Echo state networks](https://www.youtube.com/watch?v=T12mA9h1VRs&index=45&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L9 : Ways to make neural networks generalize better](https://www.youtube.com/watch?v=lbjlTd9wxWU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=53)

>* [Overview of ways to improve generalization](https://www.youtube.com/watch?v=kyuEpwOp1K0&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=47)
* [Limiting the size of the weights](https://www.youtube.com/watch?v=Gi36wfl6BAw&index=48&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
* [Using noise as a regularizer](https://www.youtube.com/watch?v=5Fveuxdg8rU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=49)
* [Introduction to the Bayesian Approach](https://www.youtube.com/watch?v=NY1zXgIma3c&index=50&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
*  [The Bayesian interpretation of weight decay](https://www.youtube.com/watch?v=KCo8h3WAClc&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=51)
* [MacKay's quick and dirty method of fixing weight costs](https://www.youtube.com/watch?v=_WZAD2uhvUM&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=52)

* L10 : Combining multiple neural networks to improve generalization
* L11 : Hopfield nets and Boltzmann machines
* L12 : Restricted Boltzmann machines (RBMs)
* L13 : Stacking RBMs to make Deep Belief Nets
* L14 : Deep neural nets with generative pre-training
* L15 : Modeling hierarchical structure with neural nets
* L16 : Recent applications of deep neural nets